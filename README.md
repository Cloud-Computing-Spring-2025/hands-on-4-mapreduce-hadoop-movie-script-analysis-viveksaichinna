# Hands-on 2: Analyzing Movie Script Dialogue Using Hadoop MapReduce

# Project Overview

This hands-on activity is designed to extend your understanding of Hadoop MapReduce by analyzing a dataset of movie script dialogues. You will implement MapReduce jobs to extract and analyze:

The most frequently spoken words by characters.

Total dialogue length per character.

Unique words used by each character.

# Approach and Implementation
Mapper Logic
Read Input: The Mapper reads each line from the movie script dialogue file.
Tokenization: The dialogue is split into words after removing special characters and punctuation.
Emit Key-Value Pairs:
For word frequency analysis: Emit (word, 1) pairs.
For dialogue length: Emit (character, dialogue_length).
For unique words per character: Emit (character, word) pairs.
Reducer Logic
Aggregate Data: The Reducer processes key-value pairs emitted by the Mapper.
Compute Results:
Most Frequent Words: Sums up occurrences of each word.
Dialogue Length Per Character: Aggregates word counts for each character.
Unique Words Per Character: Uses a set to identify unique words per character.
Output the Final Results: The results are written to HDFS for further analysis.
This implementation ensures efficient parallel processing of large movie script datasets using Hadoop MapReduce.
---

## Setup and Execution

### 1. **Fork the GitHub Repository**

- First, accept the GitHub Classroom invitation and fork the assignment repository to your own GitHub account.
- Once you’ve forked the repo, open the repository in **GitHub Codespaces** to begin working on the assignment.

---

### 2. **Start the Hadoop Cluster Using Docker Compose**

The repository contains a `docker-compose.yml` file that configures a Hadoop cluster. Run the following command in the GitHub Codespaces terminal to start the cluster:

```bash
docker-compose up -d
```

This command will spin up the necessary Hadoop components (ResourceManager, NodeManager, etc.) inside Docker containers.

---

### 3. **Build the Java Code with Maven**

After starting the cluster, use Maven to build the Java MapReduce code for the movie script analysis. In the terminal, execute the following command to compile and build the project:

```bash
mvn clean install
```

This command will generate a JAR file in the `target/` directory, which contains your MapReduce code.

---

### 4. **Prepare Input Data Files**

1. The input movie script dialogues dataset is located in the `input/` folder of the repository. Ensure that this file (`movie_dialogues.txt`) is present in the `input/` directory.

---

### 5. **Move the JAR and Input Files to the Docker Container**

#### **5.1 Move the JAR File to the Container**

Copy the built JAR file to the ResourceManager container. Run this command:

**Note**: Replace `hands-on2-movie-script-analysis-1.0-SNAPSHOT.jar` with the actual name of the JAR file generated by Maven.

```bash
docker cp target/hands-on2-movie-script-analysis-1.0-SNAPSHOT.jar resourcemanager:/opt/hadoop-3.2.1/share/hadoop/mapreduce/
```

#### **5.2 Move the Input File to the Container**

Next, copy the movie script dialogues dataset to the ResourceManager container:

```bash
docker cp input/movie_dialogues.txt resourcemanager:/opt/hadoop-3.2.1/share/hadoop/mapreduce/
```

---

### 6. **Connect to the ResourceManager Container**

To run the Hadoop commands, you'll need to connect to the ResourceManager container:

```bash
docker exec -it resourcemanager /bin/bash
```

Once inside the container, navigate to the Hadoop directory where your files were copied:

```bash
cd /opt/hadoop-3.2.1/share/hadoop/mapreduce/
```

---

### 7. **Set Up HDFS for Input File**

To run the MapReduce job, the input file needs to be stored in Hadoop’s distributed file system (HDFS).

#### **7.1 Create Directories in HDFS**

Create a directory in HDFS for the input file:

```bash
hadoop fs -mkdir -p /input/movie_scripts
```

#### **7.2 Upload the Input File to HDFS**

Upload the movie script dialogues file to HDFS:

```bash
hadoop fs -put movie_dialogues.txt /input/movie_scripts/
```

---

### 8. **Execute the Movie Script Analysis MapReduce Jobs**

Now you are ready to run your MapReduce job for movie script analysis. This job will consist of three tasks:
1. Most Frequent Words by Character
2. Dialogue Length Analysis
3. Unique Words by Character

Run the job using the following command:

**Note**: Replace `hands-on2-movie-script-analysis-1.0-SNAPSHOT.jar` with the actual name of the JAR file generated by Maven.

```bash
hadoop jar hands-on2-movie-script-analysis-1.0-SNAPSHOT.jar com.movie.script.analysis.MovieScriptAnalysis /input/movie_scripts/movie_dialogues.txt /output
```

This command will execute the MapReduce job with the movie script dialogues as the input and store the results in the `/output` directory in HDFS.

---

### 9. **View the Output of the MapReduce Job**

**Note**: The output will be stored in multiple directories (one for each task). You can view the output files using the following commands:

#### **9.1 List the Output Directories**

```bash
hadoop fs -ls /output
```

#### **9.2 View the Output Files for Each Task**

- **Task 1: Most Frequent Words by Character**
```bash
hadoop fs -cat /output/task1/part-r-00000
```

- **Task 2: Dialogue Length Analysis**
```bash
hadoop fs -cat /output/task2/part-r-00000
```

- **Task 3: Unique Words by Character**
```bash
hadoop fs -cat /output/task3/part-r-00000
```

These commands will display the results for each analysis task.

---

### 10. **Copy Output from HDFS to Local OS**

Once you have verified the results, copy the output from HDFS to your local file system.

#### **10.1 Copy Output from HDFS**

Use the following command to copy the output from HDFS to the Hadoop directory:

```bash
hadoop fs -get /output /opt/hadoop-3.2.1/share/hadoop/mapreduce/
```

#### **10.2 Copy Output from the Container to Your Local Machine**

Now, exit the ResourceManager container:

```bash
exit
```

Next, copy the output files from the Docker container to your GitHub Codespaces environment:

```bash
docker cp resourcemanager:/opt/hadoop-3.2.1/share/hadoop/mapreduce/output/ ./output/
```

---

### 11. **Submit Your Code and Output**

#### **11.1 Push Your Code and Output to GitHub**

Commit your changes, including the output from the MapReduce job, and push them to your GitHub repository:

```bash
git add .
git commit -m "Completed Movie Script Analysis Assignment"
git push origin main
```

# challenges and solution 

Challenge 1: Word Count Accuracy

During the analysis of word frequency and dialogue length, we faced an issue where punctuation (e.g., commas, periods) was being counted as part of the word. This led to inaccurate word counts.

Solution: We used a regular expression to clean the words by removing all non-alphabetical characters before counting or processing them. We also made the word comparisons case-insensitive by converting all words to lowercase.

Challenge 2: Handling Large Datasets

Given the size of movie script files, handling large datasets with MapReduce jobs could lead to excessive memory usage or long processing times.

Solution: We optimized the input by splitting the dataset into smaller chunks and used Hadoop’s distributed environment to parallelize the processing. We also ensured that the Mappers and Reducers were efficient by using HashSet for unique word collection, which ensures that memory usage is minimized.

Challenge 3: Proper Path Handling

Initially, the paths for input and output were incorrectly specified, causing job failures.

Solution: We added proper validation to check if the input and output paths were specified correctly in the args array. We also added checks for the existence of input files and output directories.


# Sample Input and Output
Hagrid: I can teach you how to bottle fame, brew glory, even put a stopper in death.
Sirius: The boy who lived, come to die.
Voldemort: Turn to page 394.
Draco: It is our choices, Harry, that show what we truly are, far more than our abilities.
Voldemort: You have your mother's eyes.
Hagrid: It does not do to dwell on dreams and forget to live.
Ron: We could all have been killed - or worse, expelled.
Draco: It's kind of fun to do the impossible.
Lupin: I am the Half-Blood Prince.
Ron: I am and always will be t

output: 

task 1

Ron:expelled.   1
Ron:face        4
Ron:fame,       3
Ron:far 6
Ron:fear        3
Ron:feel        1
Ron:find 

task 2

Draco   1014
Dumbledore      980
Hagrid  1058
Harry   758
Hermione        910
Lupin   946
Ron     1131
Sirius  847
Snape   771
Voldemort       972

task3

Draco   been don't pity your friends. finds patronum! clever you opinion, worse, going now. am - on. as at wanted wander twelve wand must looking much deal professor. be friendship. another times, turn seek increases found are does it! examined living. after you've takes a mind it. one words i right possible the call face are, to thing lived, did but bed die friendship harry, harry. language dwell do source inside good got either act habit rubber things warning up scary nerve. those us not-so-humble need this bravery. never power, name know page one. potter. little expecto expelled. idea for scary. show choose wingardium we good. not inexhaustible sorry happiness you're trouble evil. just killed. bloody live. go killed with what itself. there bravery swear years duck? leviosar! far usually truly if between there's fear in leisure. nothing mr. is come it we've even light wizard, books! love anything's differences solemnly our i'm weak us. too get remembers dark have brilliant... stand more could kill great hell! open. 394. choice impossible. fun trouble. die. severus.
